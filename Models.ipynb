{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "from keras.losses import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74732, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benchmark</th>\n",
       "      <th>year</th>\n",
       "      <th>size</th>\n",
       "      <th>memory</th>\n",
       "      <th>cycles</th>\n",
       "      <th>instructions</th>\n",
       "      <th>L1-dcache-loads</th>\n",
       "      <th>L1-dcache-load-misses</th>\n",
       "      <th>L1-dcache-stores</th>\n",
       "      <th>L1-dcache-store-misses</th>\n",
       "      <th>...</th>\n",
       "      <th>LLC-stores</th>\n",
       "      <th>LLC-store-misses</th>\n",
       "      <th>LLC-prefetches</th>\n",
       "      <th>LLC-prefetch-misses</th>\n",
       "      <th>dTLB-loads</th>\n",
       "      <th>dTLB-load-misses</th>\n",
       "      <th>dTLB-stores</th>\n",
       "      <th>dTLB-store-misses</th>\n",
       "      <th>iTLB-loads</th>\n",
       "      <th>iTLB-load-misses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perlbench</td>\n",
       "      <td>2017</td>\n",
       "      <td>test</td>\n",
       "      <td>2928</td>\n",
       "      <td>160960060</td>\n",
       "      <td>432730112</td>\n",
       "      <td>146415332</td>\n",
       "      <td>141381</td>\n",
       "      <td>41190446</td>\n",
       "      <td>58519</td>\n",
       "      <td>...</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>525</td>\n",
       "      <td>288</td>\n",
       "      <td>107894970</td>\n",
       "      <td>14</td>\n",
       "      <td>47207540</td>\n",
       "      <td>20</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perlbench</td>\n",
       "      <td>2017</td>\n",
       "      <td>test</td>\n",
       "      <td>2928</td>\n",
       "      <td>389849233</td>\n",
       "      <td>1051996693</td>\n",
       "      <td>310911945</td>\n",
       "      <td>152949</td>\n",
       "      <td>91111827</td>\n",
       "      <td>62860</td>\n",
       "      <td>...</td>\n",
       "      <td>421</td>\n",
       "      <td>115</td>\n",
       "      <td>1362</td>\n",
       "      <td>299</td>\n",
       "      <td>319136439</td>\n",
       "      <td>20</td>\n",
       "      <td>128330109</td>\n",
       "      <td>28</td>\n",
       "      <td>819</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perlbench</td>\n",
       "      <td>2017</td>\n",
       "      <td>test</td>\n",
       "      <td>2928</td>\n",
       "      <td>609008846</td>\n",
       "      <td>1644756091</td>\n",
       "      <td>447046584</td>\n",
       "      <td>162128</td>\n",
       "      <td>148757645</td>\n",
       "      <td>66175</td>\n",
       "      <td>...</td>\n",
       "      <td>546</td>\n",
       "      <td>115</td>\n",
       "      <td>1878</td>\n",
       "      <td>332</td>\n",
       "      <td>523292970</td>\n",
       "      <td>47</td>\n",
       "      <td>206012761</td>\n",
       "      <td>43</td>\n",
       "      <td>3260</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perlbench</td>\n",
       "      <td>2017</td>\n",
       "      <td>test</td>\n",
       "      <td>2928</td>\n",
       "      <td>833982652</td>\n",
       "      <td>2229230545</td>\n",
       "      <td>537877405</td>\n",
       "      <td>443035</td>\n",
       "      <td>148757645</td>\n",
       "      <td>234924</td>\n",
       "      <td>...</td>\n",
       "      <td>576</td>\n",
       "      <td>203</td>\n",
       "      <td>2493</td>\n",
       "      <td>420</td>\n",
       "      <td>727235069</td>\n",
       "      <td>74</td>\n",
       "      <td>283676211</td>\n",
       "      <td>54</td>\n",
       "      <td>4035</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perlbench</td>\n",
       "      <td>2017</td>\n",
       "      <td>test</td>\n",
       "      <td>2928</td>\n",
       "      <td>833982652</td>\n",
       "      <td>2229230545</td>\n",
       "      <td>537877405</td>\n",
       "      <td>443035</td>\n",
       "      <td>148757645</td>\n",
       "      <td>234924</td>\n",
       "      <td>...</td>\n",
       "      <td>576</td>\n",
       "      <td>203</td>\n",
       "      <td>2493</td>\n",
       "      <td>420</td>\n",
       "      <td>727235069</td>\n",
       "      <td>74</td>\n",
       "      <td>283676211</td>\n",
       "      <td>54</td>\n",
       "      <td>4035</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   benchmark  year  size  memory     cycles  instructions  L1-dcache-loads  \\\n",
       "0  perlbench  2017  test    2928  160960060     432730112        146415332   \n",
       "1  perlbench  2017  test    2928  389849233    1051996693        310911945   \n",
       "2  perlbench  2017  test    2928  609008846    1644756091        447046584   \n",
       "3  perlbench  2017  test    2928  833982652    2229230545        537877405   \n",
       "4  perlbench  2017  test    2928  833982652    2229230545        537877405   \n",
       "\n",
       "   L1-dcache-load-misses  L1-dcache-stores  L1-dcache-store-misses  \\\n",
       "0                 141381          41190446                   58519   \n",
       "1                 152949          91111827                   62860   \n",
       "2                 162128         148757645                   66175   \n",
       "3                 443035         148757645                  234924   \n",
       "4                 443035         148757645                  234924   \n",
       "\n",
       "         ...         LLC-stores  LLC-store-misses  LLC-prefetches  \\\n",
       "0        ...                162                 0             525   \n",
       "1        ...                421               115            1362   \n",
       "2        ...                546               115            1878   \n",
       "3        ...                576               203            2493   \n",
       "4        ...                576               203            2493   \n",
       "\n",
       "   LLC-prefetch-misses  dTLB-loads  dTLB-load-misses  dTLB-stores  \\\n",
       "0                  288   107894970                14     47207540   \n",
       "1                  299   319136439                20    128330109   \n",
       "2                  332   523292970                47    206012761   \n",
       "3                  420   727235069                74    283676211   \n",
       "4                  420   727235069                74    283676211   \n",
       "\n",
       "   dTLB-store-misses  iTLB-loads  iTLB-load-misses  \n",
       "0                 20         147                 1  \n",
       "1                 28         819                 4  \n",
       "2                 43        3260                 9  \n",
       "3                 54        4035                13  \n",
       "4                 54        4035                13  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in data\n",
    "data = pd.read_csv(\"./data (csv)/interval_results.csv\")\n",
    "final = pd.read_csv(\"./data (csv)/final_results.csv\")\n",
    "data = data.drop(['Unnamed: 0'], axis=1)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraph(item, benchmark, year, size):\n",
    "    sample = data[(data['benchmark']==benchmark) & (data['year']==year) & (data['size']==size)]\n",
    "    plt.plot(sample['cycles'], sample[item])\n",
    "    plt.xlabel('cycles', fontsize=14)\n",
    "    plt.ylabel(item, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotGraph('dTLB-load-misses', 'mcf', 2017, 'ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotGraph('LLC-load-misses', 'mcf', 2017, 'ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data\n",
    "data = data.dropna()\n",
    "y = data['instructions'] / data['cycles'] \n",
    "X = data.drop(['benchmark', 'year', 'size', 'memory', 'cycles', 'instructions', 'L1-dcache-prefetch-misses'], axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of IPC\n",
    "a = data['instructions'] / data['cycles']\n",
    "plt.hist(a) \n",
    "plt.title(\"histogram\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for regular testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1523948145744714"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression as baseline\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "preds = reg.predict(X_test)\n",
    "mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005916920917681436"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf = RandomForestRegressor().fit(X_train, y_train)\n",
    "preds = rf.predict(X_test)\n",
    "mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Net model\n",
    "model = Sequential()\n",
    "\n",
    "# Add first layer\n",
    "model.add(Dense(32, input_shape=(X.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add second layer\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add third layer\n",
    "model.add(Dense(1)) # regression requires just 1 \"class\"\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44839 samples, validate on 29893 samples\n",
      "Epoch 1/200\n",
      "44839/44839 [==============================] - 1s 18us/step - loss: 0.7131 - val_loss: 0.1452\n",
      "Epoch 2/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.2927 - val_loss: 0.1074\n",
      "Epoch 3/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.2307 - val_loss: 0.0930\n",
      "Epoch 4/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.1977 - val_loss: 0.0846\n",
      "Epoch 5/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.1679 - val_loss: 0.0786\n",
      "Epoch 6/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.1480 - val_loss: 0.0726\n",
      "Epoch 7/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.1257 - val_loss: 0.0637\n",
      "Epoch 8/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.1118 - val_loss: 0.0557\n",
      "Epoch 9/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0998 - val_loss: 0.0560\n",
      "Epoch 10/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0897 - val_loss: 0.0509\n",
      "Epoch 11/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0817 - val_loss: 0.0464\n",
      "Epoch 12/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0745 - val_loss: 0.0463\n",
      "Epoch 13/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0716 - val_loss: 0.0430\n",
      "Epoch 14/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0669 - val_loss: 0.0385\n",
      "Epoch 15/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0632 - val_loss: 0.0370\n",
      "Epoch 16/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0594 - val_loss: 0.0329\n",
      "Epoch 17/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0578 - val_loss: 0.0315\n",
      "Epoch 18/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0540 - val_loss: 0.0311\n",
      "Epoch 19/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0529 - val_loss: 0.0387\n",
      "Epoch 20/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0493 - val_loss: 0.0286\n",
      "Epoch 21/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0483 - val_loss: 0.0259\n",
      "Epoch 22/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0477 - val_loss: 0.0250\n",
      "Epoch 23/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0468 - val_loss: 0.0259\n",
      "Epoch 24/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0453 - val_loss: 0.0239\n",
      "Epoch 25/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0442 - val_loss: 0.0241\n",
      "Epoch 26/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0453 - val_loss: 0.0233\n",
      "Epoch 27/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0436 - val_loss: 0.0226\n",
      "Epoch 28/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0414 - val_loss: 0.0208\n",
      "Epoch 29/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0416 - val_loss: 0.0212\n",
      "Epoch 30/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0428 - val_loss: 0.0209\n",
      "Epoch 31/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0404 - val_loss: 0.0224\n",
      "Epoch 32/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0409 - val_loss: 0.0213\n",
      "Epoch 33/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0398 - val_loss: 0.0191\n",
      "Epoch 34/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0397 - val_loss: 0.0315\n",
      "Epoch 35/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0385 - val_loss: 0.0175\n",
      "Epoch 36/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0382 - val_loss: 0.0215\n",
      "Epoch 37/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0386 - val_loss: 0.0225\n",
      "Epoch 38/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0380 - val_loss: 0.0206\n",
      "Epoch 39/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0375 - val_loss: 0.0166\n",
      "Epoch 40/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0370 - val_loss: 0.0166\n",
      "Epoch 41/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0363 - val_loss: 0.0167\n",
      "Epoch 42/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0365 - val_loss: 0.0202\n",
      "Epoch 43/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0372 - val_loss: 0.0188\n",
      "Epoch 44/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0364 - val_loss: 0.0179\n",
      "Epoch 45/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0366 - val_loss: 0.0174\n",
      "Epoch 46/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0361 - val_loss: 0.0161\n",
      "Epoch 47/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0357 - val_loss: 0.0192\n",
      "Epoch 48/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0355 - val_loss: 0.0207\n",
      "Epoch 49/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0358 - val_loss: 0.0169\n",
      "Epoch 50/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0346 - val_loss: 0.0148\n",
      "Epoch 51/200\n",
      "44839/44839 [==============================] - 1s 14us/step - loss: 0.0350 - val_loss: 0.0160\n",
      "Epoch 52/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0348 - val_loss: 0.0164\n",
      "Epoch 53/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0355 - val_loss: 0.0185\n",
      "Epoch 54/200\n",
      "44839/44839 [==============================] - 1s 17us/step - loss: 0.0347 - val_loss: 0.0146\n",
      "Epoch 55/200\n",
      "44839/44839 [==============================] - 1s 14us/step - loss: 0.0335 - val_loss: 0.0169\n",
      "Epoch 56/200\n",
      "44839/44839 [==============================] - 1s 14us/step - loss: 0.0352 - val_loss: 0.0142\n",
      "Epoch 57/200\n",
      "44839/44839 [==============================] - 1s 14us/step - loss: 0.0337 - val_loss: 0.0156\n",
      "Epoch 58/200\n",
      "44839/44839 [==============================] - 1s 15us/step - loss: 0.0367 - val_loss: 0.0177\n",
      "Epoch 59/200\n",
      "44839/44839 [==============================] - 1s 13us/step - loss: 0.0348 - val_loss: 0.0123\n",
      "Epoch 60/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0338 - val_loss: 0.0146\n",
      "Epoch 61/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0349 - val_loss: 0.0154\n",
      "Epoch 62/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0342 - val_loss: 0.0142\n",
      "Epoch 63/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0344 - val_loss: 0.0161\n",
      "Epoch 64/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0350 - val_loss: 0.0178\n",
      "Epoch 65/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0342 - val_loss: 0.0132\n",
      "Epoch 66/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0333 - val_loss: 0.0192\n",
      "Epoch 67/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0335 - val_loss: 0.0163\n",
      "Epoch 68/200\n",
      "44839/44839 [==============================] - 1s 13us/step - loss: 0.0335 - val_loss: 0.0149\n",
      "Epoch 69/200\n",
      "44839/44839 [==============================] - 1s 17us/step - loss: 0.0336 - val_loss: 0.0210\n",
      "Epoch 70/200\n",
      "44839/44839 [==============================] - 1s 15us/step - loss: 0.0337 - val_loss: 0.0127\n",
      "Epoch 71/200\n",
      "44839/44839 [==============================] - 1s 13us/step - loss: 0.0347 - val_loss: 0.0179\n",
      "Epoch 72/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0332 - val_loss: 0.0176\n",
      "Epoch 73/200\n",
      "44839/44839 [==============================] - 1s 12us/step - loss: 0.0339 - val_loss: 0.0133\n",
      "Epoch 74/200\n",
      "44839/44839 [==============================] - 1s 13us/step - loss: 0.0338 - val_loss: 0.0140\n",
      "Epoch 75/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0348 - val_loss: 0.0132\n",
      "Epoch 76/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0338 - val_loss: 0.0127\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0337 - val_loss: 0.0156\n",
      "Epoch 78/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0331 - val_loss: 0.0132\n",
      "Epoch 79/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0329 - val_loss: 0.0132\n",
      "Epoch 80/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0322 - val_loss: 0.0153\n",
      "Epoch 81/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0347 - val_loss: 0.0151\n",
      "Epoch 82/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0334 - val_loss: 0.0137\n",
      "Epoch 83/200\n",
      "44839/44839 [==============================] - 1s 13us/step - loss: 0.0330 - val_loss: 0.0132\n",
      "Epoch 84/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0334 - val_loss: 0.0113\n",
      "Epoch 85/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0326 - val_loss: 0.0185\n",
      "Epoch 86/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0329 - val_loss: 0.0135\n",
      "Epoch 87/200\n",
      "44839/44839 [==============================] - 1s 11us/step - loss: 0.0332 - val_loss: 0.0132\n",
      "Epoch 88/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0343 - val_loss: 0.0175\n",
      "Epoch 89/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0319 - val_loss: 0.0124\n",
      "Epoch 90/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0319 - val_loss: 0.0137\n",
      "Epoch 91/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0346 - val_loss: 0.0349\n",
      "Epoch 92/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0350 - val_loss: 0.0136\n",
      "Epoch 93/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0320 - val_loss: 0.0137\n",
      "Epoch 94/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0338 - val_loss: 0.0147\n",
      "Epoch 95/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0324 - val_loss: 0.0139\n",
      "Epoch 96/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0331 - val_loss: 0.0152\n",
      "Epoch 97/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0345 - val_loss: 0.0148\n",
      "Epoch 98/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0322 - val_loss: 0.0144\n",
      "Epoch 99/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0324 - val_loss: 0.0140\n",
      "Epoch 100/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0327 - val_loss: 0.0169\n",
      "Epoch 101/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0323 - val_loss: 0.0132\n",
      "Epoch 102/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0328 - val_loss: 0.0140\n",
      "Epoch 103/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0335 - val_loss: 0.0120\n",
      "Epoch 104/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0325 - val_loss: 0.0119\n",
      "Epoch 105/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0325 - val_loss: 0.0142\n",
      "Epoch 106/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0332 - val_loss: 0.0142\n",
      "Epoch 107/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0338 - val_loss: 0.0159\n",
      "Epoch 108/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0323 - val_loss: 0.0124\n",
      "Epoch 109/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0315 - val_loss: 0.0150\n",
      "Epoch 110/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0323 - val_loss: 0.0164\n",
      "Epoch 111/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0329 - val_loss: 0.0128\n",
      "Epoch 112/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0330 - val_loss: 0.0121\n",
      "Epoch 113/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0334 - val_loss: 0.0196\n",
      "Epoch 114/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0327 - val_loss: 0.0158\n",
      "Epoch 115/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0326 - val_loss: 0.0136\n",
      "Epoch 116/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0315 - val_loss: 0.0199\n",
      "Epoch 117/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0323 - val_loss: 0.0151\n",
      "Epoch 118/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0324 - val_loss: 0.0173\n",
      "Epoch 119/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0317 - val_loss: 0.0165\n",
      "Epoch 120/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0326 - val_loss: 0.0140\n",
      "Epoch 121/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0330 - val_loss: 0.0152\n",
      "Epoch 122/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0314 - val_loss: 0.0172\n",
      "Epoch 123/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0318 - val_loss: 0.0117\n",
      "Epoch 124/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0314 - val_loss: 0.0131\n",
      "Epoch 125/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0323 - val_loss: 0.0145\n",
      "Epoch 126/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0315 - val_loss: 0.0144\n",
      "Epoch 127/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0315 - val_loss: 0.0182\n",
      "Epoch 128/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0314 - val_loss: 0.0169\n",
      "Epoch 129/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0323 - val_loss: 0.0199\n",
      "Epoch 130/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0326 - val_loss: 0.0127\n",
      "Epoch 131/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0311 - val_loss: 0.0139\n",
      "Epoch 132/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0317 - val_loss: 0.0175\n",
      "Epoch 133/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0317 - val_loss: 0.0125\n",
      "Epoch 134/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0308 - val_loss: 0.0110\n",
      "Epoch 135/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0327 - val_loss: 0.0141\n",
      "Epoch 136/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0318 - val_loss: 0.0135\n",
      "Epoch 137/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0328 - val_loss: 0.0158\n",
      "Epoch 138/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0320 - val_loss: 0.0121\n",
      "Epoch 139/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0326 - val_loss: 0.0162\n",
      "Epoch 140/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0319 - val_loss: 0.0117\n",
      "Epoch 141/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0313 - val_loss: 0.0123\n",
      "Epoch 142/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0306 - val_loss: 0.0140\n",
      "Epoch 143/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0307 - val_loss: 0.0117\n",
      "Epoch 144/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0318 - val_loss: 0.0137\n",
      "Epoch 145/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0312 - val_loss: 0.0125\n",
      "Epoch 146/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0315 - val_loss: 0.0124\n",
      "Epoch 147/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0302 - val_loss: 0.0174\n",
      "Epoch 148/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0322 - val_loss: 0.0145\n",
      "Epoch 149/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0312 - val_loss: 0.0117\n",
      "Epoch 150/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0309 - val_loss: 0.0129\n",
      "Epoch 151/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0316 - val_loss: 0.0141\n",
      "Epoch 152/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0325 - val_loss: 0.0115\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0311 - val_loss: 0.0134\n",
      "Epoch 154/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0313 - val_loss: 0.0145\n",
      "Epoch 155/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0320 - val_loss: 0.0138\n",
      "Epoch 156/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0310 - val_loss: 0.0116\n",
      "Epoch 157/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0319 - val_loss: 0.0154\n",
      "Epoch 158/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0314 - val_loss: 0.0117\n",
      "Epoch 159/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0310 - val_loss: 0.0133\n",
      "Epoch 160/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0310 - val_loss: 0.0117\n",
      "Epoch 161/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0307 - val_loss: 0.0114\n",
      "Epoch 162/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0312 - val_loss: 0.0115\n",
      "Epoch 163/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0317 - val_loss: 0.0112\n",
      "Epoch 164/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0302 - val_loss: 0.0122\n",
      "Epoch 165/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0310 - val_loss: 0.0172\n",
      "Epoch 166/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0319 - val_loss: 0.0139\n",
      "Epoch 167/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0313 - val_loss: 0.0154\n",
      "Epoch 168/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0326 - val_loss: 0.0153\n",
      "Epoch 169/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0308 - val_loss: 0.0132\n",
      "Epoch 170/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0316 - val_loss: 0.0127\n",
      "Epoch 171/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0314 - val_loss: 0.0191\n",
      "Epoch 172/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0314 - val_loss: 0.0126\n",
      "Epoch 173/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0316 - val_loss: 0.0157\n",
      "Epoch 174/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0299 - val_loss: 0.0107\n",
      "Epoch 175/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0303 - val_loss: 0.0130\n",
      "Epoch 176/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0302 - val_loss: 0.0179\n",
      "Epoch 177/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0308 - val_loss: 0.0140\n",
      "Epoch 178/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0313 - val_loss: 0.0111\n",
      "Epoch 179/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0314 - val_loss: 0.0148\n",
      "Epoch 180/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0304 - val_loss: 0.0137\n",
      "Epoch 181/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0324 - val_loss: 0.0108\n",
      "Epoch 182/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0313 - val_loss: 0.0136\n",
      "Epoch 183/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0316 - val_loss: 0.0108\n",
      "Epoch 184/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0311 - val_loss: 0.0148\n",
      "Epoch 185/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0296 - val_loss: 0.0105\n",
      "Epoch 186/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0322 - val_loss: 0.0115\n",
      "Epoch 187/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0317 - val_loss: 0.0202\n",
      "Epoch 188/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0309 - val_loss: 0.0105\n",
      "Epoch 189/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0308 - val_loss: 0.0186\n",
      "Epoch 190/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0311 - val_loss: 0.0141\n",
      "Epoch 191/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0309 - val_loss: 0.0172\n",
      "Epoch 192/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0300 - val_loss: 0.0175\n",
      "Epoch 193/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0308 - val_loss: 0.0115\n",
      "Epoch 194/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0314 - val_loss: 0.0149\n",
      "Epoch 195/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0314 - val_loss: 0.0111\n",
      "Epoch 196/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0312 - val_loss: 0.0153\n",
      "Epoch 197/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0298 - val_loss: 0.0124\n",
      "Epoch 198/200\n",
      "44839/44839 [==============================] - 0s 11us/step - loss: 0.0297 - val_loss: 0.0119\n",
      "Epoch 199/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0302 - val_loss: 0.0115\n",
      "Epoch 200/200\n",
      "44839/44839 [==============================] - 0s 10us/step - loss: 0.0303 - val_loss: 0.0158\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, y_train, batch_size=128,\n",
    "                    epochs=200, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6b51bbb550ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot training & validation loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data['instructions'] / data['cycles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: different benchmarks for testing and training\n",
    "def runExp12(benchmark1, benchmark2):\n",
    "    X_train = data[(data['benchmark']!=benchmark1)&(data['benchmark']!=benchmark2)].drop(['benchmark', 'year', 'size', 'memory', 'cycles', 'instructions', 'L1-dcache-prefetch-misses'], axis=1).astype(int)\n",
    "    X_test = data[(data['benchmark']==benchmark1)|(data['benchmark']==benchmark2)].drop(['benchmark', 'year', 'size', 'memory', 'cycles', 'instructions', 'L1-dcache-prefetch-misses'], axis=1).astype(int)\n",
    "    y_train = data[(data['benchmark']!=benchmark1)&(data['benchmark']!=benchmark2)]['instructions'] / data[(data['benchmark']!=benchmark1)&(data['benchmark']!=benchmark2)]['cycles']\n",
    "    y_test = data[(data['benchmark']==benchmark1)|(data['benchmark']==benchmark2)]['instructions'] / data[(data['benchmark']==benchmark1)|(data['benchmark']==benchmark2)]['cycles']\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    rf = RandomForestRegressor().fit(X_train, y_train)\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add first layer\n",
    "    model.add(Dense(32, input_shape=(X.shape[1],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Add second layer\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Add third layer\n",
    "    model.add(Dense(1)) # regression requires just 1 \"class\"\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    history = model.fit(X_train, y_train, batch_size=128,\n",
    "                        epochs=200)\n",
    "    X_test = sc.transform(X_test)\n",
    "    lin_preds = reg.predict(X_test)\n",
    "    print(mean_squared_error(y_test, lin_preds))\n",
    "    rf_preds = rf.predict(X_test)\n",
    "    print(mean_squared_error(y_test, rf_preds))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(mean_squared_error(y_test, y_pred.flatten()))\n",
    "    \n",
    "    \n",
    "\n",
    "def runExp13(benchmark1, benchmark2, benchmark3):\n",
    "    X_train = data[(data['benchmark']!=benchmark1)&(data['benchmark']!=benchmark2)&(data['benchmark']!=benchmark3)].drop(['benchmark', 'year', 'size', 'memory', 'cycles', 'instructions', 'L1-dcache-prefetch-misses'], axis=1).astype(int)\n",
    "    X_test = data[(data['benchmark']==benchmark1)|(data['benchmark']==benchmark2)|(data['benchmark']==benchmark3)].drop(['benchmark', 'year', 'size', 'memory', 'cycles', 'instructions', 'L1-dcache-prefetch-misses'], axis=1).astype(int)\n",
    "    y_train = data[(data['benchmark']!=benchmark1)&(data['benchmark']!=benchmark2)&(data['benchmark']!=benchmark3)]['instructions'] / data[(data['benchmark']!=benchmark1)&(data['benchmark']!=benchmark2)&(data['benchmark']!=benchmark3)]['cycles']\n",
    "    y_test =data[(data['benchmark']==benchmark1)|(data['benchmark']==benchmark2)|(data['benchmark']==benchmark3)]['instructions'] / data[(data['benchmark']==benchmark1)|(data['benchmark']==benchmark2)|(data['benchmark']==benchmark3)]['cycles']\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    rf = RandomForestRegressor().fit(X_train, y_train)\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add first layer\n",
    "    model.add(Dense(32, input_shape=(X.shape[1],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Add second layer\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Add third layer\n",
    "    model.add(Dense(1)) # regression requires just 1 \"class\"\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    history = model.fit(X_train, y_train, batch_size=128,\n",
    "                        epochs=200)\n",
    "    X_test = sc.transform(X_test)\n",
    "    lin_preds = reg.predict(X_test)\n",
    "    print(mean_squared_error(y_test, lin_preds))\n",
    "    rf_preds = rf.predict(X_test)\n",
    "    print(mean_squared_error(y_test, rf_preds))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(mean_squared_error(y_test, y_pred.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fp', 'mcf']\n",
      "Epoch 1/200\n",
      "62743/62743 [==============================] - 1s 17us/step - loss: 0.6821\n",
      "Epoch 2/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.2052\n",
      "Epoch 3/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.1507\n",
      "Epoch 4/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.1200\n",
      "Epoch 5/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.1017\n",
      "Epoch 6/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0870\n",
      "Epoch 7/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0747\n",
      "Epoch 8/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0647\n",
      "Epoch 9/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0583\n",
      "Epoch 10/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0541\n",
      "Epoch 11/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0514\n",
      "Epoch 12/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0497\n",
      "Epoch 13/200\n",
      "62743/62743 [==============================] - 1s 10us/step - loss: 0.0471\n",
      "Epoch 14/200\n",
      "62743/62743 [==============================] - 1s 10us/step - loss: 0.0459\n",
      "Epoch 15/200\n",
      "62743/62743 [==============================] - 1s 11us/step - loss: 0.0446\n",
      "Epoch 16/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0429\n",
      "Epoch 17/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0412\n",
      "Epoch 18/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0401\n",
      "Epoch 19/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0395\n",
      "Epoch 20/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0380\n",
      "Epoch 21/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0364\n",
      "Epoch 22/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0354\n",
      "Epoch 23/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0339\n",
      "Epoch 24/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0334\n",
      "Epoch 25/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0325\n",
      "Epoch 26/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0313\n",
      "Epoch 27/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0302\n",
      "Epoch 28/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 29/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0288\n",
      "Epoch 30/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0292\n",
      "Epoch 31/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0285\n",
      "Epoch 32/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0279\n",
      "Epoch 33/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0270\n",
      "Epoch 34/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0267\n",
      "Epoch 35/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0263\n",
      "Epoch 36/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0270\n",
      "Epoch 37/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0271\n",
      "Epoch 38/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0266\n",
      "Epoch 39/200\n",
      "62743/62743 [==============================] - 1s 10us/step - loss: 0.0260\n",
      "Epoch 40/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0264\n",
      "Epoch 41/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0265\n",
      "Epoch 42/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0255\n",
      "Epoch 43/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0258\n",
      "Epoch 44/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0258\n",
      "Epoch 45/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0249\n",
      "Epoch 46/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0277\n",
      "Epoch 47/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0279\n",
      "Epoch 48/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0262\n",
      "Epoch 49/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0258\n",
      "Epoch 50/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0255\n",
      "Epoch 51/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0255\n",
      "Epoch 52/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0269\n",
      "Epoch 53/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0260\n",
      "Epoch 54/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0260\n",
      "Epoch 55/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0258\n",
      "Epoch 56/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0253\n",
      "Epoch 57/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0262\n",
      "Epoch 58/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0254\n",
      "Epoch 59/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0262\n",
      "Epoch 60/200\n",
      "62743/62743 [==============================] - 1s 10us/step - loss: 0.0255\n",
      "Epoch 61/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0249\n",
      "Epoch 62/200\n",
      "62743/62743 [==============================] - 1s 10us/step - loss: 0.0259\n",
      "Epoch 63/200\n",
      "62743/62743 [==============================] - 1s 10us/step - loss: 0.0252\n",
      "Epoch 64/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0250\n",
      "Epoch 65/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0248\n",
      "Epoch 66/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0262\n",
      "Epoch 67/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0248\n",
      "Epoch 68/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0258\n",
      "Epoch 69/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0253\n",
      "Epoch 70/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0247\n",
      "Epoch 71/200\n",
      "62743/62743 [==============================] - 1s 10us/step - loss: 0.0255\n",
      "Epoch 72/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0251\n",
      "Epoch 73/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0257\n",
      "Epoch 74/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0252\n",
      "Epoch 75/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0236\n",
      "Epoch 76/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0255\n",
      "Epoch 77/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0253\n",
      "Epoch 78/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0252\n",
      "Epoch 79/200\n",
      "62743/62743 [==============================] - 1s 10us/step - loss: 0.0250\n",
      "Epoch 80/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0244\n",
      "Epoch 81/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0248\n",
      "Epoch 82/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0246\n",
      "Epoch 83/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0243\n",
      "Epoch 84/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0246\n",
      "Epoch 85/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0247\n",
      "Epoch 86/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0245\n",
      "Epoch 87/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0239\n",
      "Epoch 88/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0256\n",
      "Epoch 89/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0257\n",
      "Epoch 90/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0260\n",
      "Epoch 91/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0253\n",
      "Epoch 92/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0251\n",
      "Epoch 93/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0253\n",
      "Epoch 94/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0243\n",
      "Epoch 96/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0242\n",
      "Epoch 97/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0236\n",
      "Epoch 98/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0245\n",
      "Epoch 99/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0238\n",
      "Epoch 100/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0248\n",
      "Epoch 101/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0238\n",
      "Epoch 102/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0245\n",
      "Epoch 103/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0241\n",
      "Epoch 104/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0231\n",
      "Epoch 105/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0247\n",
      "Epoch 106/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0241\n",
      "Epoch 107/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0246\n",
      "Epoch 108/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0242\n",
      "Epoch 109/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0238\n",
      "Epoch 110/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0240\n",
      "Epoch 111/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0242\n",
      "Epoch 112/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0244\n",
      "Epoch 113/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0236\n",
      "Epoch 114/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0240\n",
      "Epoch 115/200\n",
      "62743/62743 [==============================] - 1s 10us/step - loss: 0.0245\n",
      "Epoch 116/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0235\n",
      "Epoch 117/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0241\n",
      "Epoch 118/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0247\n",
      "Epoch 119/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0234\n",
      "Epoch 120/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0241\n",
      "Epoch 121/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0237\n",
      "Epoch 122/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0236\n",
      "Epoch 123/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0241\n",
      "Epoch 124/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0242\n",
      "Epoch 125/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0240\n",
      "Epoch 126/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0239\n",
      "Epoch 127/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0244\n",
      "Epoch 128/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0242\n",
      "Epoch 129/200\n",
      "62743/62743 [==============================] - 1s 8us/step - loss: 0.0239\n",
      "Epoch 130/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0246\n",
      "Epoch 131/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0246\n",
      "Epoch 132/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0240\n",
      "Epoch 133/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0235\n",
      "Epoch 134/200\n",
      "62743/62743 [==============================] - 1s 8us/step - loss: 0.0243\n",
      "Epoch 135/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0239\n",
      "Epoch 136/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0237\n",
      "Epoch 137/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0238\n",
      "Epoch 138/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0248\n",
      "Epoch 139/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0243\n",
      "Epoch 140/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0239\n",
      "Epoch 141/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0247\n",
      "Epoch 142/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0234\n",
      "Epoch 143/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0234\n",
      "Epoch 144/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0239\n",
      "Epoch 145/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0235\n",
      "Epoch 146/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0235\n",
      "Epoch 147/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0232\n",
      "Epoch 148/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0234\n",
      "Epoch 149/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0232\n",
      "Epoch 150/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0232\n",
      "Epoch 151/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0233\n",
      "Epoch 152/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0240\n",
      "Epoch 153/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0232\n",
      "Epoch 154/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0232\n",
      "Epoch 155/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0233\n",
      "Epoch 156/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0239\n",
      "Epoch 157/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0231\n",
      "Epoch 158/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0233\n",
      "Epoch 159/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0226\n",
      "Epoch 160/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0234\n",
      "Epoch 161/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0226\n",
      "Epoch 162/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0234\n",
      "Epoch 163/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0230\n",
      "Epoch 164/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0226\n",
      "Epoch 165/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0229\n",
      "Epoch 166/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0229\n",
      "Epoch 167/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0236\n",
      "Epoch 168/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0232\n",
      "Epoch 169/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0229\n",
      "Epoch 170/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0233\n",
      "Epoch 171/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0228\n",
      "Epoch 172/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0223\n",
      "Epoch 173/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0229\n",
      "Epoch 174/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0230\n",
      "Epoch 175/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0228\n",
      "Epoch 176/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0226\n",
      "Epoch 177/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0231\n",
      "Epoch 178/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0234\n",
      "Epoch 179/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0239\n",
      "Epoch 180/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0224\n",
      "Epoch 181/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0228\n",
      "Epoch 182/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0230\n",
      "Epoch 183/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0224\n",
      "Epoch 184/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0224\n",
      "Epoch 185/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0226\n",
      "Epoch 186/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0222\n",
      "Epoch 187/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0224\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0224\n",
      "Epoch 189/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0227\n",
      "Epoch 190/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0220\n",
      "Epoch 191/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0229\n",
      "Epoch 192/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0232\n",
      "Epoch 193/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0228\n",
      "Epoch 194/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0227\n",
      "Epoch 195/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0230\n",
      "Epoch 196/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0220\n",
      "Epoch 197/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0220\n",
      "Epoch 198/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0234\n",
      "Epoch 199/200\n",
      "62743/62743 [==============================] - 1s 8us/step - loss: 0.0220\n",
      "Epoch 200/200\n",
      "62743/62743 [==============================] - 1s 9us/step - loss: 0.0234\n",
      "0.7578676305743897\n",
      "0.851259634886323\n",
      "0.7422143684120333\n",
      "['libquantum', 'omnetpp']\n",
      "Epoch 1/200\n",
      "65408/65408 [==============================] - 1s 16us/step - loss: 0.4954\n",
      "Epoch 2/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.2085\n",
      "Epoch 3/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.1649\n",
      "Epoch 4/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.1337\n",
      "Epoch 5/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.1115\n",
      "Epoch 6/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0946\n",
      "Epoch 7/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0830\n",
      "Epoch 8/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0728\n",
      "Epoch 9/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0657\n",
      "Epoch 10/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0601\n",
      "Epoch 11/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0562\n",
      "Epoch 12/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0530\n",
      "Epoch 13/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0506\n",
      "Epoch 14/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0495\n",
      "Epoch 15/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0464\n",
      "Epoch 16/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0448\n",
      "Epoch 17/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0435\n",
      "Epoch 18/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0421\n",
      "Epoch 19/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0403\n",
      "Epoch 20/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0390\n",
      "Epoch 21/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0388\n",
      "Epoch 22/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0378\n",
      "Epoch 23/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0379\n",
      "Epoch 24/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0363\n",
      "Epoch 25/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0351\n",
      "Epoch 26/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0336\n",
      "Epoch 27/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0343\n",
      "Epoch 28/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0334\n",
      "Epoch 29/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0326\n",
      "Epoch 30/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0318\n",
      "Epoch 31/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0326\n",
      "Epoch 32/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0322\n",
      "Epoch 33/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0323\n",
      "Epoch 34/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0321\n",
      "Epoch 35/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0328\n",
      "Epoch 36/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0325\n",
      "Epoch 37/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0311\n",
      "Epoch 38/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0314\n",
      "Epoch 39/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0311\n",
      "Epoch 40/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0312\n",
      "Epoch 41/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0301\n",
      "Epoch 42/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0318\n",
      "Epoch 43/200\n",
      "65408/65408 [==============================] - 1s 12us/step - loss: 0.0324\n",
      "Epoch 44/200\n",
      "65408/65408 [==============================] - 1s 12us/step - loss: 0.0322\n",
      "Epoch 45/200\n",
      "65408/65408 [==============================] - 1s 13us/step - loss: 0.0310\n",
      "Epoch 46/200\n",
      "65408/65408 [==============================] - 1s 12us/step - loss: 0.0323\n",
      "Epoch 47/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0312\n",
      "Epoch 48/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0314\n",
      "Epoch 49/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0316\n",
      "Epoch 50/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0305\n",
      "Epoch 51/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0313\n",
      "Epoch 52/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0304\n",
      "Epoch 53/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0315\n",
      "Epoch 54/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0307\n",
      "Epoch 55/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0312\n",
      "Epoch 56/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0312\n",
      "Epoch 57/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0319\n",
      "Epoch 58/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0314\n",
      "Epoch 59/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0313\n",
      "Epoch 60/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0313\n",
      "Epoch 61/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0318\n",
      "Epoch 62/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0309\n",
      "Epoch 63/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0298\n",
      "Epoch 64/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0311\n",
      "Epoch 65/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0307\n",
      "Epoch 66/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 67/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0302\n",
      "Epoch 68/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0306\n",
      "Epoch 69/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 70/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0295\n",
      "Epoch 71/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0301\n",
      "Epoch 72/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0307\n",
      "Epoch 73/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0304\n",
      "Epoch 74/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0297\n",
      "Epoch 75/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0300\n",
      "Epoch 76/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0306\n",
      "Epoch 77/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0322\n",
      "Epoch 78/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0306\n",
      "Epoch 79/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0315\n",
      "Epoch 80/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0302\n",
      "Epoch 81/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0304\n",
      "Epoch 82/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0293\n",
      "Epoch 83/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0301\n",
      "Epoch 84/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0306\n",
      "Epoch 85/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0295\n",
      "Epoch 86/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0296\n",
      "Epoch 87/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 88/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0300\n",
      "Epoch 89/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0304\n",
      "Epoch 90/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0298\n",
      "Epoch 91/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0307\n",
      "Epoch 92/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0311\n",
      "Epoch 93/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0299\n",
      "Epoch 94/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0315\n",
      "Epoch 95/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 96/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 97/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0309\n",
      "Epoch 98/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0296\n",
      "Epoch 99/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0294\n",
      "Epoch 100/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0301\n",
      "Epoch 101/200\n",
      "65408/65408 [==============================] - 1s 12us/step - loss: 0.0311\n",
      "Epoch 102/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0311\n",
      "Epoch 103/200\n",
      "65408/65408 [==============================] - 1s 11us/step - loss: 0.0290\n",
      "Epoch 104/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0290\n",
      "Epoch 105/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0296\n",
      "Epoch 106/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0296\n",
      "Epoch 107/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0299\n",
      "Epoch 108/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0301\n",
      "Epoch 109/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0292\n",
      "Epoch 110/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0296\n",
      "Epoch 111/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0297\n",
      "Epoch 112/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0309\n",
      "Epoch 113/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0308\n",
      "Epoch 114/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0320\n",
      "Epoch 115/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0301\n",
      "Epoch 116/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 117/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0302\n",
      "Epoch 118/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0307\n",
      "Epoch 119/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0298\n",
      "Epoch 120/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 121/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 122/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 123/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0300\n",
      "Epoch 124/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0299\n",
      "Epoch 125/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0306\n",
      "Epoch 126/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0300\n",
      "Epoch 127/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0298\n",
      "Epoch 128/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0298\n",
      "Epoch 129/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 130/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0299\n",
      "Epoch 131/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0295\n",
      "Epoch 132/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0300\n",
      "Epoch 133/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0298\n",
      "Epoch 134/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0301\n",
      "Epoch 135/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 136/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0298\n",
      "Epoch 137/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0294\n",
      "Epoch 138/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 139/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0292\n",
      "Epoch 140/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 141/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0301\n",
      "Epoch 142/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0295\n",
      "Epoch 143/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0290\n",
      "Epoch 144/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0294\n",
      "Epoch 145/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 146/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 147/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 148/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0302\n",
      "Epoch 149/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0310\n",
      "Epoch 150/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 151/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0290\n",
      "Epoch 152/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0292\n",
      "Epoch 153/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 154/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0290\n",
      "Epoch 155/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0287\n",
      "Epoch 156/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0287\n",
      "Epoch 157/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0294\n",
      "Epoch 158/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0295\n",
      "Epoch 159/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0286\n",
      "Epoch 160/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0293\n",
      "Epoch 161/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 162/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0294\n",
      "Epoch 163/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0294\n",
      "Epoch 164/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0289\n",
      "Epoch 165/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0300\n",
      "Epoch 166/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0282\n",
      "Epoch 167/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0288\n",
      "Epoch 168/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0286\n",
      "Epoch 169/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0289\n",
      "Epoch 170/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0304\n",
      "Epoch 171/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0289\n",
      "Epoch 172/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0290\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0290\n",
      "Epoch 174/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0291\n",
      "Epoch 175/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0293\n",
      "Epoch 176/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0302\n",
      "Epoch 177/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0291\n",
      "Epoch 178/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0283\n",
      "Epoch 179/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0287\n",
      "Epoch 180/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 181/200\n",
      "65408/65408 [==============================] - 1s 10us/step - loss: 0.0284\n",
      "Epoch 182/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0281\n",
      "Epoch 183/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0286\n",
      "Epoch 184/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0288\n",
      "Epoch 185/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0283\n",
      "Epoch 186/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0296\n",
      "Epoch 187/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0295\n",
      "Epoch 188/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0288\n",
      "Epoch 189/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0286\n",
      "Epoch 190/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0290\n",
      "Epoch 191/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0283\n",
      "Epoch 192/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0294\n",
      "Epoch 193/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0292\n",
      "Epoch 194/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 195/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0289\n",
      "Epoch 196/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0292\n",
      "Epoch 197/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 198/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0291\n",
      "Epoch 199/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 200/200\n",
      "65408/65408 [==============================] - 1s 9us/step - loss: 0.0284\n",
      "78.37930162954828\n",
      "0.6997986156404105\n",
      "0.29385610390262323\n",
      "['gcc', 'sjeng']\n",
      "Epoch 1/200\n",
      "62094/62094 [==============================] - 1s 17us/step - loss: 0.6529\n",
      "Epoch 2/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.2207\n",
      "Epoch 3/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.1643\n",
      "Epoch 4/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.1290\n",
      "Epoch 5/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.1088\n",
      "Epoch 6/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0943\n",
      "Epoch 7/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0850\n",
      "Epoch 8/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0770\n",
      "Epoch 9/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0708\n",
      "Epoch 10/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0645\n",
      "Epoch 11/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0604\n",
      "Epoch 12/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0576\n",
      "Epoch 13/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0565\n",
      "Epoch 14/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0531\n",
      "Epoch 15/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0518\n",
      "Epoch 16/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0505\n",
      "Epoch 17/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0487\n",
      "Epoch 18/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0480\n",
      "Epoch 19/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0463\n",
      "Epoch 20/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0450\n",
      "Epoch 21/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0444\n",
      "Epoch 22/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0435\n",
      "Epoch 23/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0423\n",
      "Epoch 24/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0414\n",
      "Epoch 25/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0407\n",
      "Epoch 26/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0405\n",
      "Epoch 27/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0402\n",
      "Epoch 28/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0392\n",
      "Epoch 29/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0382\n",
      "Epoch 30/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0385\n",
      "Epoch 31/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0385\n",
      "Epoch 32/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0376\n",
      "Epoch 33/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0392\n",
      "Epoch 34/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0390\n",
      "Epoch 35/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0364\n",
      "Epoch 36/200\n",
      "62094/62094 [==============================] - 1s 12us/step - loss: 0.0372\n",
      "Epoch 37/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0376\n",
      "Epoch 38/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0372\n",
      "Epoch 39/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0373\n",
      "Epoch 40/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0375\n",
      "Epoch 41/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0364\n",
      "Epoch 42/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0377\n",
      "Epoch 43/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0377\n",
      "Epoch 44/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0381\n",
      "Epoch 45/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0398\n",
      "Epoch 46/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0381\n",
      "Epoch 47/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0373\n",
      "Epoch 48/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0373\n",
      "Epoch 49/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0372\n",
      "Epoch 50/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 51/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0369\n",
      "Epoch 52/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 53/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0370\n",
      "Epoch 54/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0373\n",
      "Epoch 55/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 56/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0375\n",
      "Epoch 57/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0371\n",
      "Epoch 58/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 59/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0370\n",
      "Epoch 60/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 61/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0356\n",
      "Epoch 62/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0370\n",
      "Epoch 63/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0368\n",
      "Epoch 64/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0353\n",
      "Epoch 65/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0373\n",
      "Epoch 66/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0354\n",
      "Epoch 67/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0361\n",
      "Epoch 68/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0362\n",
      "Epoch 69/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0353\n",
      "Epoch 70/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0351\n",
      "Epoch 71/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 72/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0370\n",
      "Epoch 73/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 74/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0348\n",
      "Epoch 75/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 76/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0344\n",
      "Epoch 77/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0354\n",
      "Epoch 78/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0355\n",
      "Epoch 79/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0344\n",
      "Epoch 80/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0355\n",
      "Epoch 81/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0350\n",
      "Epoch 82/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0348\n",
      "Epoch 83/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0347\n",
      "Epoch 84/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0354\n",
      "Epoch 85/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0349\n",
      "Epoch 86/200\n",
      "62094/62094 [==============================] - 1s 12us/step - loss: 0.0360\n",
      "Epoch 87/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0357\n",
      "Epoch 88/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 89/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0343\n",
      "Epoch 90/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0339\n",
      "Epoch 91/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0352\n",
      "Epoch 92/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0338\n",
      "Epoch 93/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0353\n",
      "Epoch 94/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0344\n",
      "Epoch 95/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0349\n",
      "Epoch 96/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0342\n",
      "Epoch 97/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0343\n",
      "Epoch 98/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0342\n",
      "Epoch 99/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0349\n",
      "Epoch 100/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0336\n",
      "Epoch 101/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0350\n",
      "Epoch 102/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0332\n",
      "Epoch 103/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0350\n",
      "Epoch 104/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0346\n",
      "Epoch 105/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0344\n",
      "Epoch 106/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 107/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0352\n",
      "Epoch 108/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0345\n",
      "Epoch 109/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0342\n",
      "Epoch 110/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0376\n",
      "Epoch 111/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0357\n",
      "Epoch 112/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0356\n",
      "Epoch 113/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0353\n",
      "Epoch 114/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0353\n",
      "Epoch 115/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0339\n",
      "Epoch 116/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0345\n",
      "Epoch 117/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 118/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0341\n",
      "Epoch 119/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0339\n",
      "Epoch 120/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0342\n",
      "Epoch 121/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0344\n",
      "Epoch 122/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0338\n",
      "Epoch 123/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0340\n",
      "Epoch 124/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0344\n",
      "Epoch 125/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0335\n",
      "Epoch 126/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0328\n",
      "Epoch 127/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0343\n",
      "Epoch 128/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0331\n",
      "Epoch 129/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0329\n",
      "Epoch 130/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0349\n",
      "Epoch 131/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0360\n",
      "Epoch 132/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0332\n",
      "Epoch 133/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0334\n",
      "Epoch 134/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0344\n",
      "Epoch 135/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0331\n",
      "Epoch 136/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0332\n",
      "Epoch 137/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0346\n",
      "Epoch 138/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0333\n",
      "Epoch 139/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0326\n",
      "Epoch 140/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0335\n",
      "Epoch 141/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0335\n",
      "Epoch 142/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0334\n",
      "Epoch 143/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0328\n",
      "Epoch 144/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0337\n",
      "Epoch 145/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0330\n",
      "Epoch 146/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0323\n",
      "Epoch 147/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0342\n",
      "Epoch 148/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0339\n",
      "Epoch 149/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0337\n",
      "Epoch 150/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0335\n",
      "Epoch 151/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0336\n",
      "Epoch 152/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0328\n",
      "Epoch 153/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0340\n",
      "Epoch 154/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0332\n",
      "Epoch 155/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0340\n",
      "Epoch 156/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0339\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0323\n",
      "Epoch 158/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0332\n",
      "Epoch 159/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0337\n",
      "Epoch 160/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0332\n",
      "Epoch 161/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0324\n",
      "Epoch 162/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0338\n",
      "Epoch 163/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0328\n",
      "Epoch 164/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0339\n",
      "Epoch 165/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0329\n",
      "Epoch 166/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0334\n",
      "Epoch 167/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0331\n",
      "Epoch 168/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0330\n",
      "Epoch 169/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0327\n",
      "Epoch 170/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0332\n",
      "Epoch 171/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0325\n",
      "Epoch 172/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0325\n",
      "Epoch 173/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0316\n",
      "Epoch 174/200\n",
      "62094/62094 [==============================] - 1s 11us/step - loss: 0.0323\n",
      "Epoch 175/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0324\n",
      "Epoch 176/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0326\n",
      "Epoch 177/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0321\n",
      "Epoch 178/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0326\n",
      "Epoch 179/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0332\n",
      "Epoch 180/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0333\n",
      "Epoch 181/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0338\n",
      "Epoch 182/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0323\n",
      "Epoch 183/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0324\n",
      "Epoch 184/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0330\n",
      "Epoch 185/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0333\n",
      "Epoch 186/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0325\n",
      "Epoch 187/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0328\n",
      "Epoch 188/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0342\n",
      "Epoch 189/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0327\n",
      "Epoch 190/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0324\n",
      "Epoch 191/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0325\n",
      "Epoch 192/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0321\n",
      "Epoch 193/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0319\n",
      "Epoch 194/200\n",
      "62094/62094 [==============================] - 1s 10us/step - loss: 0.0315\n",
      "Epoch 195/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0326\n",
      "Epoch 196/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0329\n",
      "Epoch 197/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0328\n",
      "Epoch 198/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0324\n",
      "Epoch 199/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0320\n",
      "Epoch 200/200\n",
      "62094/62094 [==============================] - 1s 9us/step - loss: 0.0332\n",
      "7.243772449712039\n",
      "0.43781160367185024\n",
      "1.7143901919398925\n",
      "['astar', 'perlbench']\n",
      "Epoch 1/200\n",
      "68139/68139 [==============================] - 1s 17us/step - loss: 0.4659\n",
      "Epoch 2/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.1858\n",
      "Epoch 3/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.1489\n",
      "Epoch 4/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.1213\n",
      "Epoch 5/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0977\n",
      "Epoch 6/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0843\n",
      "Epoch 7/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0767\n",
      "Epoch 8/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0707\n",
      "Epoch 9/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0635\n",
      "Epoch 10/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0594\n",
      "Epoch 11/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0557\n",
      "Epoch 12/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0530\n",
      "Epoch 13/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0506\n",
      "Epoch 14/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0473\n",
      "Epoch 15/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0463\n",
      "Epoch 16/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0446\n",
      "Epoch 17/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0431\n",
      "Epoch 18/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0418\n",
      "Epoch 19/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0403\n",
      "Epoch 20/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0393\n",
      "Epoch 21/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0376\n",
      "Epoch 22/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0366\n",
      "Epoch 23/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0364\n",
      "Epoch 24/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0357\n",
      "Epoch 25/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 26/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0349\n",
      "Epoch 27/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0341\n",
      "Epoch 28/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0347\n",
      "Epoch 29/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0333\n",
      "Epoch 30/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0334\n",
      "Epoch 31/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0322\n",
      "Epoch 32/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0326\n",
      "Epoch 33/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0332\n",
      "Epoch 34/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0335\n",
      "Epoch 35/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0327\n",
      "Epoch 36/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0332\n",
      "Epoch 37/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0323\n",
      "Epoch 38/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0311\n",
      "Epoch 39/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0316\n",
      "Epoch 40/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0311\n",
      "Epoch 41/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0319\n",
      "Epoch 42/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0306\n",
      "Epoch 43/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0299\n",
      "Epoch 44/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0306\n",
      "Epoch 45/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0310\n",
      "Epoch 46/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0295\n",
      "Epoch 47/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0306\n",
      "Epoch 48/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 49/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0301\n",
      "Epoch 50/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 51/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0296\n",
      "Epoch 52/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0293\n",
      "Epoch 53/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0299\n",
      "Epoch 54/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0300\n",
      "Epoch 55/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0292\n",
      "Epoch 56/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0294\n",
      "Epoch 57/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0308\n",
      "Epoch 58/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0288\n",
      "Epoch 59/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0309\n",
      "Epoch 60/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0298\n",
      "Epoch 61/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0292\n",
      "Epoch 62/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0313\n",
      "Epoch 63/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0306\n",
      "Epoch 64/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0314\n",
      "Epoch 65/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0311\n",
      "Epoch 66/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0312\n",
      "Epoch 67/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0315\n",
      "Epoch 68/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0302\n",
      "Epoch 69/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0314\n",
      "Epoch 70/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0305\n",
      "Epoch 71/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0298\n",
      "Epoch 72/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0311\n",
      "Epoch 73/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0309\n",
      "Epoch 74/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0296\n",
      "Epoch 75/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0310\n",
      "Epoch 76/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0311\n",
      "Epoch 77/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0291\n",
      "Epoch 78/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0308\n",
      "Epoch 79/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0316\n",
      "Epoch 80/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0307\n",
      "Epoch 81/200\n",
      "68139/68139 [==============================] - 1s 12us/step - loss: 0.0309\n",
      "Epoch 82/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0308\n",
      "Epoch 83/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0294\n",
      "Epoch 84/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0290\n",
      "Epoch 85/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0298\n",
      "Epoch 86/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0284\n",
      "Epoch 87/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0301\n",
      "Epoch 88/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0299\n",
      "Epoch 89/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0309\n",
      "Epoch 90/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0298\n",
      "Epoch 91/200\n",
      "68139/68139 [==============================] - 1s 12us/step - loss: 0.0297\n",
      "Epoch 92/200\n",
      "68139/68139 [==============================] - 1s 12us/step - loss: 0.0297\n",
      "Epoch 93/200\n",
      "68139/68139 [==============================] - 1s 12us/step - loss: 0.0295\n",
      "Epoch 94/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0285\n",
      "Epoch 95/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0300\n",
      "Epoch 96/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0299\n",
      "Epoch 97/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0302\n",
      "Epoch 98/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0293\n",
      "Epoch 99/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0306\n",
      "Epoch 100/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0305\n",
      "Epoch 101/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0296\n",
      "Epoch 102/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0292\n",
      "Epoch 103/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0294\n",
      "Epoch 104/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0308\n",
      "Epoch 105/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0298\n",
      "Epoch 106/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0287\n",
      "Epoch 107/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0293\n",
      "Epoch 108/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0300\n",
      "Epoch 109/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0293\n",
      "Epoch 110/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0288\n",
      "Epoch 111/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0289\n",
      "Epoch 112/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0296\n",
      "Epoch 113/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0291\n",
      "Epoch 114/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0306\n",
      "Epoch 115/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0285\n",
      "Epoch 116/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0285\n",
      "Epoch 117/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0293\n",
      "Epoch 118/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0293\n",
      "Epoch 119/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0289\n",
      "Epoch 120/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0281\n",
      "Epoch 121/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0293\n",
      "Epoch 122/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0316\n",
      "Epoch 123/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0299\n",
      "Epoch 124/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0302\n",
      "Epoch 125/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0297\n",
      "Epoch 126/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0314\n",
      "Epoch 127/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0305\n",
      "Epoch 128/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0318\n",
      "Epoch 129/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0292\n",
      "Epoch 130/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0293\n",
      "Epoch 131/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0303\n",
      "Epoch 132/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0297\n",
      "Epoch 133/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0291\n",
      "Epoch 134/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0286\n",
      "Epoch 135/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0283\n",
      "Epoch 136/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0287\n",
      "Epoch 137/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0284\n",
      "Epoch 138/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0308\n",
      "Epoch 139/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0302\n",
      "Epoch 140/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0296\n",
      "Epoch 141/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0314\n",
      "Epoch 143/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0301\n",
      "Epoch 144/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0302\n",
      "Epoch 145/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0297\n",
      "Epoch 146/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 147/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0287\n",
      "Epoch 148/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0294\n",
      "Epoch 149/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0293\n",
      "Epoch 150/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0293\n",
      "Epoch 151/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0289\n",
      "Epoch 152/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0287\n",
      "Epoch 153/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0288\n",
      "Epoch 154/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0290\n",
      "Epoch 155/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0289\n",
      "Epoch 156/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 157/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0291\n",
      "Epoch 158/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0282\n",
      "Epoch 159/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0292\n",
      "Epoch 160/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0284\n",
      "Epoch 161/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0287\n",
      "Epoch 162/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0296\n",
      "Epoch 163/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0308\n",
      "Epoch 164/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0285\n",
      "Epoch 165/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0290\n",
      "Epoch 166/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0289\n",
      "Epoch 167/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0294\n",
      "Epoch 168/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0293\n",
      "Epoch 169/200\n",
      "68139/68139 [==============================] - 1s 11us/step - loss: 0.0286\n",
      "Epoch 170/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0284\n",
      "Epoch 171/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0280\n",
      "Epoch 172/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0276\n",
      "Epoch 173/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0274\n",
      "Epoch 174/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0274\n",
      "Epoch 175/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0295\n",
      "Epoch 176/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0293\n",
      "Epoch 177/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0295\n",
      "Epoch 178/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0296\n",
      "Epoch 179/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0295\n",
      "Epoch 180/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0298\n",
      "Epoch 181/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0282\n",
      "Epoch 182/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0282\n",
      "Epoch 183/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0273\n",
      "Epoch 184/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0274\n",
      "Epoch 185/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0293\n",
      "Epoch 186/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0301\n",
      "Epoch 187/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0298\n",
      "Epoch 188/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0294\n",
      "Epoch 189/200\n",
      "68139/68139 [==============================] - 1s 10us/step - loss: 0.0294\n",
      "Epoch 190/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 191/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0302\n",
      "Epoch 192/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0299\n",
      "Epoch 193/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0297\n",
      "Epoch 194/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0301\n",
      "Epoch 195/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 196/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0309\n",
      "Epoch 197/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0285\n",
      "Epoch 198/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0296\n",
      "Epoch 199/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0288\n",
      "Epoch 200/200\n",
      "68139/68139 [==============================] - 1s 9us/step - loss: 0.0287\n",
      "3.365709651099365\n",
      "0.43755920341181614\n",
      "0.34913414485758504\n",
      "['deepsjeng', 'leela']\n",
      "Epoch 1/200\n",
      "72993/72993 [==============================] - 1s 19us/step - loss: 0.6324\n",
      "Epoch 2/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.2090\n",
      "Epoch 3/200\n",
      "72993/72993 [==============================] - 1s 12us/step - loss: 0.1639\n",
      "Epoch 4/200\n",
      "72993/72993 [==============================] - 1s 12us/step - loss: 0.1327\n",
      "Epoch 5/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.1070\n",
      "Epoch 6/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0897\n",
      "Epoch 7/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0759\n",
      "Epoch 8/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0653\n",
      "Epoch 9/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0593\n",
      "Epoch 10/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0550\n",
      "Epoch 11/200\n",
      "72993/72993 [==============================] - 1s 12us/step - loss: 0.0499\n",
      "Epoch 12/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0471\n",
      "Epoch 13/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0435\n",
      "Epoch 14/200\n",
      "72993/72993 [==============================] - 1s 12us/step - loss: 0.0417\n",
      "Epoch 15/200\n",
      "72993/72993 [==============================] - 1s 12us/step - loss: 0.0397\n",
      "Epoch 16/200\n",
      "72993/72993 [==============================] - 1s 12us/step - loss: 0.0388\n",
      "Epoch 17/200\n",
      "72993/72993 [==============================] - 1s 16us/step - loss: 0.0370\n",
      "Epoch 18/200\n",
      "72993/72993 [==============================] - 1s 13us/step - loss: 0.0357\n",
      "Epoch 19/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0346\n",
      "Epoch 20/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0337\n",
      "Epoch 21/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0340\n",
      "Epoch 22/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0335\n",
      "Epoch 23/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0325\n",
      "Epoch 24/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0318\n",
      "Epoch 25/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0311\n",
      "Epoch 26/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0313\n",
      "Epoch 27/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0314\n",
      "Epoch 28/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0311\n",
      "Epoch 29/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0304\n",
      "Epoch 30/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0305\n",
      "Epoch 31/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0299: 0s - loss: 0.0\n",
      "Epoch 32/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0299\n",
      "Epoch 33/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0296\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0300\n",
      "Epoch 35/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0302\n",
      "Epoch 36/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0291\n",
      "Epoch 37/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0293\n",
      "Epoch 38/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0289\n",
      "Epoch 39/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0284\n",
      "Epoch 40/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0291\n",
      "Epoch 41/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0290\n",
      "Epoch 42/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0296\n",
      "Epoch 43/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0293\n",
      "Epoch 44/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0289\n",
      "Epoch 45/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0291\n",
      "Epoch 46/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0291\n",
      "Epoch 47/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0283\n",
      "Epoch 48/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0288\n",
      "Epoch 49/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0287\n",
      "Epoch 50/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0286\n",
      "Epoch 51/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0289\n",
      "Epoch 52/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0279\n",
      "Epoch 53/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0277\n",
      "Epoch 54/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0284\n",
      "Epoch 55/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0282\n",
      "Epoch 56/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0283\n",
      "Epoch 57/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0285\n",
      "Epoch 58/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0281\n",
      "Epoch 59/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0289\n",
      "Epoch 60/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0278\n",
      "Epoch 61/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0285\n",
      "Epoch 62/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0277\n",
      "Epoch 63/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0274\n",
      "Epoch 64/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0291\n",
      "Epoch 65/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0275\n",
      "Epoch 66/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0283\n",
      "Epoch 67/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0279\n",
      "Epoch 68/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0279\n",
      "Epoch 69/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0295\n",
      "Epoch 70/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0278\n",
      "Epoch 71/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0273\n",
      "Epoch 72/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0282\n",
      "Epoch 73/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0278\n",
      "Epoch 74/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0270\n",
      "Epoch 75/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0277\n",
      "Epoch 76/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0270\n",
      "Epoch 77/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0270\n",
      "Epoch 78/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0274\n",
      "Epoch 79/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0275\n",
      "Epoch 80/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0281\n",
      "Epoch 81/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0283\n",
      "Epoch 82/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0274\n",
      "Epoch 83/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0275\n",
      "Epoch 84/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0280\n",
      "Epoch 85/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0269\n",
      "Epoch 86/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0273\n",
      "Epoch 87/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0277\n",
      "Epoch 88/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0281\n",
      "Epoch 89/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0270\n",
      "Epoch 90/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0267\n",
      "Epoch 91/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0275\n",
      "Epoch 92/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0276\n",
      "Epoch 93/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0286\n",
      "Epoch 94/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0273\n",
      "Epoch 95/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0268\n",
      "Epoch 96/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0278\n",
      "Epoch 97/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0272\n",
      "Epoch 98/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0261\n",
      "Epoch 99/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0267\n",
      "Epoch 100/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0266\n",
      "Epoch 101/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0271\n",
      "Epoch 102/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0267\n",
      "Epoch 103/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0269\n",
      "Epoch 104/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0277\n",
      "Epoch 105/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0265\n",
      "Epoch 106/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0271\n",
      "Epoch 107/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0269\n",
      "Epoch 108/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0264\n",
      "Epoch 109/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0273\n",
      "Epoch 110/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0264\n",
      "Epoch 111/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0273\n",
      "Epoch 112/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0272\n",
      "Epoch 113/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0280\n",
      "Epoch 114/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0265\n",
      "Epoch 115/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0267\n",
      "Epoch 116/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0269\n",
      "Epoch 117/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0269\n",
      "Epoch 118/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0267\n",
      "Epoch 119/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0264\n",
      "Epoch 120/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0271\n",
      "Epoch 121/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0265\n",
      "Epoch 122/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0264\n",
      "Epoch 123/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0276\n",
      "Epoch 124/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0264\n",
      "Epoch 125/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0270\n",
      "Epoch 126/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0267\n",
      "Epoch 127/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0272\n",
      "Epoch 128/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0265\n",
      "Epoch 129/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0265\n",
      "Epoch 130/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0269\n",
      "Epoch 131/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0262\n",
      "Epoch 132/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0271\n",
      "Epoch 133/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0265\n",
      "Epoch 134/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0265\n",
      "Epoch 135/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0261\n",
      "Epoch 136/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0264\n",
      "Epoch 137/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0260\n",
      "Epoch 138/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0260\n",
      "Epoch 139/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0267\n",
      "Epoch 140/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0263\n",
      "Epoch 141/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0267\n",
      "Epoch 142/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0262\n",
      "Epoch 143/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0262\n",
      "Epoch 144/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0270\n",
      "Epoch 145/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0271\n",
      "Epoch 146/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0266\n",
      "Epoch 147/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0263\n",
      "Epoch 148/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0262\n",
      "Epoch 149/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0258\n",
      "Epoch 150/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0260\n",
      "Epoch 151/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0261\n",
      "Epoch 152/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0262\n",
      "Epoch 153/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0257\n",
      "Epoch 154/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0260\n",
      "Epoch 155/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0255\n",
      "Epoch 156/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0263\n",
      "Epoch 157/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0254\n",
      "Epoch 158/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0262\n",
      "Epoch 159/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0262\n",
      "Epoch 160/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0259\n",
      "Epoch 161/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0261\n",
      "Epoch 162/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0255\n",
      "Epoch 163/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0254\n",
      "Epoch 164/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0257\n",
      "Epoch 165/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0260\n",
      "Epoch 166/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0256\n",
      "Epoch 167/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0254\n",
      "Epoch 168/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0266\n",
      "Epoch 169/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0259\n",
      "Epoch 170/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0270\n",
      "Epoch 171/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0262\n",
      "Epoch 172/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0257\n",
      "Epoch 173/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0266\n",
      "Epoch 174/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0253\n",
      "Epoch 175/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0259\n",
      "Epoch 176/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0255\n",
      "Epoch 177/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0259\n",
      "Epoch 178/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0258\n",
      "Epoch 179/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0259\n",
      "Epoch 180/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0259\n",
      "Epoch 181/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0252\n",
      "Epoch 182/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0261\n",
      "Epoch 183/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0257\n",
      "Epoch 184/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0261\n",
      "Epoch 185/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0265\n",
      "Epoch 186/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0260\n",
      "Epoch 187/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0262\n",
      "Epoch 188/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0259\n",
      "Epoch 189/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0257\n",
      "Epoch 190/200\n",
      "72993/72993 [==============================] - 1s 11us/step - loss: 0.0263\n",
      "Epoch 191/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0252\n",
      "Epoch 192/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0253\n",
      "Epoch 193/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0251\n",
      "Epoch 194/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0257\n",
      "Epoch 195/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0252\n",
      "Epoch 196/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0258\n",
      "Epoch 197/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0258\n",
      "Epoch 198/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0256\n",
      "Epoch 199/200\n",
      "72993/72993 [==============================] - 1s 9us/step - loss: 0.0255\n",
      "Epoch 200/200\n",
      "72993/72993 [==============================] - 1s 10us/step - loss: 0.0259\n",
      "0.22908270642160378\n",
      "0.9213309336009843\n",
      "0.5716385075791038\n",
      "['xalancbmk', 'bzip2', 'h264ref']\n",
      "Epoch 1/200\n",
      "61316/61316 [==============================] - 1s 19us/step - loss: 0.4333\n",
      "Epoch 2/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.1768\n",
      "Epoch 3/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.1353\n",
      "Epoch 4/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.1089\n",
      "Epoch 5/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0886\n",
      "Epoch 6/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0764\n",
      "Epoch 7/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0715\n",
      "Epoch 8/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0669\n",
      "Epoch 9/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0626\n",
      "Epoch 10/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0590\n",
      "Epoch 11/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0562\n",
      "Epoch 12/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0554\n",
      "Epoch 13/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0518\n",
      "Epoch 14/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0505\n",
      "Epoch 15/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0491\n",
      "Epoch 16/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0490\n",
      "Epoch 17/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0479\n",
      "Epoch 18/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0457\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0447\n",
      "Epoch 20/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0433\n",
      "Epoch 21/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0422\n",
      "Epoch 22/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0404\n",
      "Epoch 23/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0398\n",
      "Epoch 24/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0386\n",
      "Epoch 25/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0383\n",
      "Epoch 26/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 27/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0353\n",
      "Epoch 28/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0351\n",
      "Epoch 29/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 30/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0350\n",
      "Epoch 31/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0372\n",
      "Epoch 32/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0360\n",
      "Epoch 33/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0353\n",
      "Epoch 34/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0355\n",
      "Epoch 35/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0336\n",
      "Epoch 36/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0337\n",
      "Epoch 37/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0336\n",
      "Epoch 38/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0333\n",
      "Epoch 39/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0329\n",
      "Epoch 40/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0333\n",
      "Epoch 41/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0333\n",
      "Epoch 42/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0328\n",
      "Epoch 43/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0329\n",
      "Epoch 44/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0330\n",
      "Epoch 45/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0320\n",
      "Epoch 46/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0316\n",
      "Epoch 47/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0324\n",
      "Epoch 48/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0319\n",
      "Epoch 49/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0319\n",
      "Epoch 50/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0325\n",
      "Epoch 51/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0324\n",
      "Epoch 52/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0329\n",
      "Epoch 53/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0323\n",
      "Epoch 54/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0324\n",
      "Epoch 55/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0324\n",
      "Epoch 56/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0319\n",
      "Epoch 57/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0315\n",
      "Epoch 58/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0316\n",
      "Epoch 59/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0313\n",
      "Epoch 60/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0313\n",
      "Epoch 61/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0314\n",
      "Epoch 62/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0315\n",
      "Epoch 63/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0317\n",
      "Epoch 64/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0319\n",
      "Epoch 65/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0310\n",
      "Epoch 66/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0302\n",
      "Epoch 67/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0320\n",
      "Epoch 68/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0315\n",
      "Epoch 69/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0314\n",
      "Epoch 70/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0307\n",
      "Epoch 71/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0308\n",
      "Epoch 72/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0310\n",
      "Epoch 73/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0307\n",
      "Epoch 74/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0314\n",
      "Epoch 75/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0310\n",
      "Epoch 76/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0310\n",
      "Epoch 77/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 78/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0308\n",
      "Epoch 79/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0314\n",
      "Epoch 80/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 81/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0314\n",
      "Epoch 82/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0302\n",
      "Epoch 83/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0301\n",
      "Epoch 84/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0303\n",
      "Epoch 85/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0312\n",
      "Epoch 86/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0316\n",
      "Epoch 87/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0307\n",
      "Epoch 88/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0301\n",
      "Epoch 89/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0306\n",
      "Epoch 90/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0295\n",
      "Epoch 91/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0304\n",
      "Epoch 92/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0304\n",
      "Epoch 93/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0301\n",
      "Epoch 94/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0311\n",
      "Epoch 95/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0329\n",
      "Epoch 96/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0306\n",
      "Epoch 97/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0306\n",
      "Epoch 98/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0313\n",
      "Epoch 99/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0312\n",
      "Epoch 100/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0325\n",
      "Epoch 101/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0319\n",
      "Epoch 102/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0341\n",
      "Epoch 103/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0330\n",
      "Epoch 104/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0307\n",
      "Epoch 105/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0312\n",
      "Epoch 106/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0309\n",
      "Epoch 107/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0308\n",
      "Epoch 108/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0318\n",
      "Epoch 109/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0308\n",
      "Epoch 110/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 111/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 112/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 113/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0308\n",
      "Epoch 114/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 115/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0304\n",
      "Epoch 116/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0306\n",
      "Epoch 117/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0305\n",
      "Epoch 118/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0307\n",
      "Epoch 119/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0301\n",
      "Epoch 120/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0298\n",
      "Epoch 121/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0303\n",
      "Epoch 122/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0303\n",
      "Epoch 123/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0304\n",
      "Epoch 124/200\n",
      "61316/61316 [==============================] - 1s 9us/step - loss: 0.0310\n",
      "Epoch 125/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0317\n",
      "Epoch 126/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0304\n",
      "Epoch 127/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0292\n",
      "Epoch 128/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0299\n",
      "Epoch 129/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0302\n",
      "Epoch 130/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0385\n",
      "Epoch 131/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0295\n",
      "Epoch 132/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0295\n",
      "Epoch 133/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0294\n",
      "Epoch 134/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0295\n",
      "Epoch 135/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0298\n",
      "Epoch 136/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0304\n",
      "Epoch 137/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0296\n",
      "Epoch 138/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0302\n",
      "Epoch 139/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0294: 0s - loss: 0.029\n",
      "Epoch 140/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0305\n",
      "Epoch 141/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0300\n",
      "Epoch 142/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0305\n",
      "Epoch 143/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0294\n",
      "Epoch 144/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0300\n",
      "Epoch 145/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0303\n",
      "Epoch 146/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0314\n",
      "Epoch 147/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0296\n",
      "Epoch 148/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0295\n",
      "Epoch 149/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0304\n",
      "Epoch 150/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0303\n",
      "Epoch 151/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0304\n",
      "Epoch 152/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0298\n",
      "Epoch 153/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0300\n",
      "Epoch 154/200\n",
      "61316/61316 [==============================] - 1s 10us/step - loss: 0.0351\n",
      "Epoch 155/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0292\n",
      "Epoch 156/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0298\n",
      "Epoch 157/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0297\n",
      "Epoch 158/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0301\n",
      "Epoch 159/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0299\n",
      "Epoch 160/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0288\n",
      "Epoch 161/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0304\n",
      "Epoch 162/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0294\n",
      "Epoch 163/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0291\n",
      "Epoch 164/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0311\n",
      "Epoch 165/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0305\n",
      "Epoch 166/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0300\n",
      "Epoch 167/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0301\n",
      "Epoch 168/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0291\n",
      "Epoch 169/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0308\n",
      "Epoch 170/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0305\n",
      "Epoch 171/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0291\n",
      "Epoch 172/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0307\n",
      "Epoch 173/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0312\n",
      "Epoch 174/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0301\n",
      "Epoch 175/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0294\n",
      "Epoch 176/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0298\n",
      "Epoch 177/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0293\n",
      "Epoch 178/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0294\n",
      "Epoch 179/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0350\n",
      "Epoch 180/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0328\n",
      "Epoch 181/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0310\n",
      "Epoch 182/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0302\n",
      "Epoch 183/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0285\n",
      "Epoch 184/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0292\n",
      "Epoch 185/200\n",
      "61316/61316 [==============================] - 1s 13us/step - loss: 0.0291\n",
      "Epoch 186/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0302\n",
      "Epoch 187/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0292\n",
      "Epoch 188/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0290\n",
      "Epoch 189/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0289\n",
      "Epoch 190/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0286\n",
      "Epoch 191/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0288\n",
      "Epoch 192/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0295\n",
      "Epoch 193/200\n",
      "61316/61316 [==============================] - 1s 12us/step - loss: 0.0288\n",
      "Epoch 194/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0296\n",
      "Epoch 195/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0308\n",
      "Epoch 196/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0295\n",
      "Epoch 197/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0286\n",
      "Epoch 198/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0297\n",
      "Epoch 199/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0295\n",
      "Epoch 200/200\n",
      "61316/61316 [==============================] - 1s 11us/step - loss: 0.0292\n",
      "0.6095695150095\n",
      "0.44995383631339436\n",
      "0.4813652024456479\n",
      "['gobmk', 'hmmer', 'exchange2']\n",
      "Epoch 1/200\n",
      "55699/55699 [==============================] - 2s 30us/step - loss: 0.4730\n",
      "Epoch 2/200\n",
      "55699/55699 [==============================] - 1s 14us/step - loss: 0.1880\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.1402\n",
      "Epoch 4/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.1159\n",
      "Epoch 5/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0982\n",
      "Epoch 6/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0865\n",
      "Epoch 7/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0782\n",
      "Epoch 8/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0724\n",
      "Epoch 9/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0671\n",
      "Epoch 10/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0643\n",
      "Epoch 11/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0591\n",
      "Epoch 12/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0560\n",
      "Epoch 13/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0526\n",
      "Epoch 14/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0516\n",
      "Epoch 15/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0487\n",
      "Epoch 16/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0470\n",
      "Epoch 17/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0459\n",
      "Epoch 18/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0440\n",
      "Epoch 19/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0420\n",
      "Epoch 20/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0406\n",
      "Epoch 21/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0406\n",
      "Epoch 22/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0393\n",
      "Epoch 23/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0386\n",
      "Epoch 24/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0395\n",
      "Epoch 25/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0376\n",
      "Epoch 26/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0369\n",
      "Epoch 27/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0375\n",
      "Epoch 28/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0372\n",
      "Epoch 29/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0368\n",
      "Epoch 30/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0347\n",
      "Epoch 31/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0356\n",
      "Epoch 32/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 33/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 34/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0348\n",
      "Epoch 35/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0349\n",
      "Epoch 36/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0339\n",
      "Epoch 37/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 38/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0355\n",
      "Epoch 39/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0348\n",
      "Epoch 40/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0339\n",
      "Epoch 41/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0349\n",
      "Epoch 42/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0335\n",
      "Epoch 43/200\n",
      "55699/55699 [==============================] - 1s 16us/step - loss: 0.0348\n",
      "Epoch 44/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0331\n",
      "Epoch 45/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0330\n",
      "Epoch 46/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0326\n",
      "Epoch 47/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0335\n",
      "Epoch 48/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0325\n",
      "Epoch 49/200\n",
      "55699/55699 [==============================] - 1s 9us/step - loss: 0.0329\n",
      "Epoch 50/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0338\n",
      "Epoch 51/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0335\n",
      "Epoch 52/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0341\n",
      "Epoch 53/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0338\n",
      "Epoch 54/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0322\n",
      "Epoch 55/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0339\n",
      "Epoch 56/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0341\n",
      "Epoch 57/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0323\n",
      "Epoch 58/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0323\n",
      "Epoch 59/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0324\n",
      "Epoch 60/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0327\n",
      "Epoch 61/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0315\n",
      "Epoch 62/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0338\n",
      "Epoch 63/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0322\n",
      "Epoch 64/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0332\n",
      "Epoch 65/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0316\n",
      "Epoch 66/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0332\n",
      "Epoch 67/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0321\n",
      "Epoch 68/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0335\n",
      "Epoch 69/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0325\n",
      "Epoch 70/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0318\n",
      "Epoch 71/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0314\n",
      "Epoch 72/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0328\n",
      "Epoch 73/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0337\n",
      "Epoch 74/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0336\n",
      "Epoch 75/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0323\n",
      "Epoch 76/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0329\n",
      "Epoch 77/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0316\n",
      "Epoch 78/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0324\n",
      "Epoch 79/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0327\n",
      "Epoch 80/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0333\n",
      "Epoch 81/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0324\n",
      "Epoch 82/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0313\n",
      "Epoch 83/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0327\n",
      "Epoch 84/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0341\n",
      "Epoch 85/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0332\n",
      "Epoch 86/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0340\n",
      "Epoch 87/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0323\n",
      "Epoch 88/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0318\n",
      "Epoch 89/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0328\n",
      "Epoch 90/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0326\n",
      "Epoch 91/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0325\n",
      "Epoch 92/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0309\n",
      "Epoch 93/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0325\n",
      "Epoch 94/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0311\n",
      "Epoch 95/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0310\n",
      "Epoch 96/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0328\n",
      "Epoch 97/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0334\n",
      "Epoch 98/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0328\n",
      "Epoch 99/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0325\n",
      "Epoch 100/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0326\n",
      "Epoch 101/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0325\n",
      "Epoch 102/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0319\n",
      "Epoch 103/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0313\n",
      "Epoch 104/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0329\n",
      "Epoch 105/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0312\n",
      "Epoch 106/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0308\n",
      "Epoch 107/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0320\n",
      "Epoch 108/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0310\n",
      "Epoch 109/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0314\n",
      "Epoch 110/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0307\n",
      "Epoch 111/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0328\n",
      "Epoch 112/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0317\n",
      "Epoch 113/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0326\n",
      "Epoch 114/200\n",
      "55699/55699 [==============================] - 1s 14us/step - loss: 0.0310\n",
      "Epoch 115/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0321\n",
      "Epoch 116/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0299\n",
      "Epoch 117/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0328\n",
      "Epoch 118/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0322\n",
      "Epoch 119/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0323\n",
      "Epoch 120/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0320\n",
      "Epoch 121/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0303\n",
      "Epoch 122/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0310\n",
      "Epoch 123/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0306\n",
      "Epoch 124/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0304\n",
      "Epoch 125/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0314\n",
      "Epoch 126/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0306\n",
      "Epoch 127/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0311\n",
      "Epoch 128/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0317\n",
      "Epoch 129/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0313\n",
      "Epoch 130/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0315\n",
      "Epoch 131/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0322\n",
      "Epoch 132/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0309\n",
      "Epoch 133/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0314\n",
      "Epoch 134/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0316\n",
      "Epoch 135/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0324\n",
      "Epoch 136/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0311\n",
      "Epoch 137/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0307\n",
      "Epoch 138/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0311\n",
      "Epoch 139/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0306\n",
      "Epoch 140/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0302\n",
      "Epoch 141/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0310\n",
      "Epoch 142/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0311\n",
      "Epoch 143/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0300\n",
      "Epoch 144/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0311\n",
      "Epoch 145/200\n",
      "55699/55699 [==============================] - 1s 14us/step - loss: 0.0320\n",
      "Epoch 146/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0309\n",
      "Epoch 147/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0305\n",
      "Epoch 148/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0324\n",
      "Epoch 149/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0313\n",
      "Epoch 150/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0302\n",
      "Epoch 151/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0301\n",
      "Epoch 152/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0304\n",
      "Epoch 153/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0300\n",
      "Epoch 154/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0310\n",
      "Epoch 155/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0304\n",
      "Epoch 156/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0309\n",
      "Epoch 157/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0311\n",
      "Epoch 158/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0305\n",
      "Epoch 159/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0303\n",
      "Epoch 160/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0309\n",
      "Epoch 161/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0308\n",
      "Epoch 162/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0308\n",
      "Epoch 163/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0309\n",
      "Epoch 164/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0304\n",
      "Epoch 165/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0304\n",
      "Epoch 166/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0301\n",
      "Epoch 167/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0306\n",
      "Epoch 168/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0299\n",
      "Epoch 169/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0302\n",
      "Epoch 170/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0305\n",
      "Epoch 171/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0312\n",
      "Epoch 172/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0305\n",
      "Epoch 173/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0308\n",
      "Epoch 174/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0308\n",
      "Epoch 175/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0309\n",
      "Epoch 176/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0303\n",
      "Epoch 177/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0310\n",
      "Epoch 178/200\n",
      "55699/55699 [==============================] - 1s 13us/step - loss: 0.0289\n",
      "Epoch 179/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0311\n",
      "Epoch 180/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0297\n",
      "Epoch 181/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0300\n",
      "Epoch 182/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0295\n",
      "Epoch 183/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0299\n",
      "Epoch 184/200\n",
      "55699/55699 [==============================] - 1s 12us/step - loss: 0.0291\n",
      "Epoch 185/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0296\n",
      "Epoch 186/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0301\n",
      "Epoch 187/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0311\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0308\n",
      "Epoch 189/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0300\n",
      "Epoch 190/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0303\n",
      "Epoch 191/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0304\n",
      "Epoch 192/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0312\n",
      "Epoch 193/200\n",
      "55699/55699 [==============================] - 1s 11us/step - loss: 0.0298\n",
      "Epoch 194/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0304\n",
      "Epoch 195/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0305\n",
      "Epoch 196/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0298\n",
      "Epoch 197/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0306\n",
      "Epoch 198/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0306\n",
      "Epoch 199/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0304\n",
      "Epoch 200/200\n",
      "55699/55699 [==============================] - 1s 10us/step - loss: 0.0299\n",
      "37.01958205423471\n",
      "0.31794721896314654\n",
      "1.9836905081078322\n"
     ]
    }
   ],
   "source": [
    "# Run experiment 1\n",
    "twolist = [['fp', 'mcf'], ['libquantum', 'omnetpp'], ['gcc', 'sjeng'], ['astar', 'perlbench'], ['deepsjeng', 'leela']]\n",
    "threelist = [['xalancbmk', 'bzip2', 'h264ref'], ['gobmk', 'hmmer', 'exchange2']]\n",
    "\n",
    "for twos in twolist:\n",
    "    print(twos)\n",
    "    runExp12(twos[0], twos[1])\n",
    "    \n",
    "for threes in threelist:\n",
    "    print(threes)\n",
    "    runExp13(threes[0], threes[1], threes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: train on 'ref' and test on 'test' and 'train' for each benchmark\n",
    "def runExp2(benchmark, year):\n",
    "    X_test = data[(data['size']!='ref')&(data['benchmark']==benchmark)&(data['year']==year)].drop(['benchmark', 'year', 'size', 'memory', 'cycles', 'instructions', 'L1-dcache-prefetch-misses'], axis=1).astype(int)\n",
    "    y_test = data[(data['size']!='ref')&(data['benchmark']==benchmark)&(data['year']==year)]['instructions'] / data[(data['size']!='ref')&(data['benchmark']==benchmark)&(data['year']==year)]['cycles']\n",
    "    X_test = sc.transform(X_test)\n",
    "    lin_preds = reg.predict(X_test)\n",
    "    print(mean_squared_error(y_test, lin_preds))\n",
    "    rf_preds = rf.predict(X_test)\n",
    "    print(mean_squared_error(y_test, rf_preds))\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(mean_squared_error(y_test, y_pred.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perlbench\n",
      "2017\n",
      "0.8029353089000179\n",
      "0.32805605747025335\n",
      "0.8815343546519622\n",
      "gcc\n",
      "2017\n",
      "0.005550347231433918\n",
      "0.05601405136321615\n",
      "0.08579612933992078\n",
      "mcf\n",
      "2017\n",
      "0.5593367741503098\n",
      "0.8463426679530224\n",
      "0.007512329687789915\n",
      "omnetpp\n",
      "2017\n",
      "0.3080985285034185\n",
      "0.0006487497046105236\n",
      "0.0069251306934266345\n",
      "xalancbmk\n",
      "2017\n",
      "0.2812184678958795\n",
      "0.023434250810233218\n",
      "0.0745533370225974\n",
      "deepsjeng\n",
      "2017\n",
      "0.21547059975625993\n",
      "0.24140425133755597\n",
      "0.2834598221125204\n",
      "leela\n",
      "2017\n",
      "0.10708945323140748\n",
      "0.8838646973825586\n",
      "0.750907768820328\n",
      "exchange2\n",
      "2017\n",
      "0.31365525854616544\n",
      "0.00022544558806185616\n",
      "0.05196594502757291\n",
      "fp\n",
      "2017\n",
      "0.93782693420357\n",
      "1.9100222543127707\n",
      "0.319977276307206\n",
      "perlbench\n",
      "2006\n",
      "0.4555837645800316\n",
      "0.12159374058745946\n",
      "0.42791850509165236\n",
      "bzip2\n",
      "2006\n",
      "0.029283429582773513\n",
      "0.24447410426021696\n",
      "0.08842596522445574\n",
      "gcc\n",
      "2006\n",
      "0.014811125464410692\n",
      "0.023366848273003744\n",
      "0.07937292695374583\n",
      "gobmk\n",
      "2006\n",
      "0.07458997639018902\n",
      "0.03249073422548369\n",
      "0.021642723427628408\n",
      "hmmer\n",
      "2006\n",
      "0.33664714313700367\n",
      "0.018524861171887404\n",
      "0.10853672332332256\n",
      "sjeng\n",
      "2006\n",
      "0.00667897974031385\n",
      "0.005825607744575365\n",
      "0.014722745997566945\n",
      "h264ref\n",
      "2006\n",
      "0.9259256678451471\n",
      "0.07810889217431441\n",
      "0.22025370402609346\n",
      "astar\n",
      "2006\n",
      "0.3669479462388689\n",
      "0.4399259209994977\n",
      "0.045528934902358424\n",
      "omnetpp\n",
      "2006\n",
      "0.18293584270569474\n",
      "0.10459781346817676\n",
      "0.47618847411972487\n",
      "libquantum\n",
      "2006\n",
      "1.2579478385475493\n",
      "0.6333439809481489\n",
      "1.5541718023848312\n",
      "mcf\n",
      "2006\n",
      "1.0484176669952174\n",
      "1.0494890539579587\n",
      "0.21205640295574593\n"
     ]
    }
   ],
   "source": [
    "# Run Experiment 2\n",
    "year = 2017\n",
    "for benchmark in ['perlbench', 'gcc', 'mcf', 'omnetpp', 'xalancbmk', 'deepsjeng', 'leela', 'exchange2', 'fp']:\n",
    "    print(benchmark)\n",
    "    print(year)\n",
    "    runExp2(benchmark, year)\n",
    "    \n",
    "year = 2006\n",
    "for benchmark in ['perlbench', 'bzip2', 'gcc', 'gobmk', 'hmmer', 'sjeng', 'h264ref', 'astar', 'omnetpp', 'libquantum', 'mcf']:\n",
    "    print(benchmark)\n",
    "    print(year)\n",
    "    runExp2(benchmark, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3: different percentages of start and end for different benchmarks\n",
    "\n",
    "#['perlbench', 'gcc', 'mcf', 'omnetpp', 'xalancbmk', 'deepsjeng', 'leela', 'exchange2', 'fp', 'bzip2', 'gobmk', 'hmmer', 'sjeng', 'h264ref', 'astar', 'libquantum']\n",
    "train = pd.DataFrame(columns=data.columns.values)\n",
    "for benchmark in ['perlbench', 'gcc', 'mcf', 'omnetpp', 'xalancbmk', 'deepsjeng', 'leela', 'exchange2', 'fp', 'bzip2', 'gobmk', 'hmmer', 'sjeng', 'h264ref', 'astar', 'libquantum']:\n",
    "    for size in ['ref', 'train', 'test']:\n",
    "        percent = 0.8\n",
    "        benchmark_data = data[(data['benchmark']==benchmark)&(data['size']==size)]\n",
    "        nrows = int(benchmark_data.shape[0] * percent)\n",
    "        train = train.append(benchmark_data[:nrows])\n",
    "\n",
    "X_train = train.drop(['benchmark', 'year', 'size', 'memory', 'cycles', 'instructions', 'L1-dcache-prefetch-misses'], axis=1).astype(int)\n",
    "y_train = train['instructions'] / train['cycles']\n",
    "\n",
    "test = pd.DataFrame(columns=data.columns.values)\n",
    "for benchmark in ['perlbench', 'gcc', 'mcf', 'omnetpp', 'xalancbmk', 'deepsjeng', 'leela', 'exchange2', 'fp', 'bzip2', 'gobmk', 'hmmer', 'sjeng', 'h264ref', 'astar', 'libquantum']:\n",
    "    for size in ['ref', 'train', 'test']:\n",
    "        percent = 0.9\n",
    "        benchmark_data = data[(data['benchmark']==benchmark)&(data['size']==size)]\n",
    "        nrows = int(benchmark_data.shape[0] * percent)\n",
    "        test = test.append(benchmark_data[nrows:])\n",
    "\n",
    "X_test = test.drop(['benchmark', 'year', 'size', 'memory', 'cycles', 'instructions', 'L1-dcache-prefetch-misses'], axis=1).astype(int)\n",
    "y_test = test['instructions'] / test['cycles']   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
